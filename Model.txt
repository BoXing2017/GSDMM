package main;

import java.io.BufferedWriter;
import java.io.File;
import java.io.FileOutputStream;
import java.io.OutputStreamWriter;

public class Model{
	int K; //K is the number of the clusters(random initialized)
	double alpha;
	double beta;
	String dataset;
	String ParametersStr;
	int V; //number of the word in the vocabulary(different word)
	int D; //number of the document in the corpus
	int iterNum; 
	double alpha0;
	double beta0;
	double[][] phi_zv;
	int[] z; 
	int[] m_z; //number of document in cluster z
	int[][] n_zv//two dimension array that denote the number of word w in cluster z.
	int[] n_z; //number of word in cluster z
	double smallDouble = 1e-150;
	double largeDouble = 1e150;

	public Model(int K, int V, int iterNum, double alpha, double beta, 
			String dataset, String ParametersStr)
	{
		this.dataset = dataset;
		this.ParametersStr = ParametersStr;
		this.alpha = alpha;
		this.beta = beta;
		this.K = K; //number of mixture components(cluster)
		this.V = V;// number of words?Or what is V?
		this.iterNum = iterNum;//How can we determine the number of iteration?
		this.alpha0 = K * alpha;
		this.beta0 = V * beta;
		
		this.m_z = new int[K];
		this.n_z = new int[K];
		this.n_zv = new int[K][V];
		for(int k = 0; k < K; k++){
			this.n_z[k] = 0;
			this.m_z[k] = 0;
			for(int t = 0; t < V; t++){
				this.n_zv[k][t] = 0;
			}
		}
	}//构造方法
	public void intialize(DocumentSet documentSet)
	{
		D = documentSet.D;
		z = new int[D];
		for(int d = 0; d < D; d++){
			Document document = documentSet.documents.get(d);
			int cluster = (int) (K * Math.random());
			z[d] = cluster;
			m_z[cluster]++;
			for(int w = 0; w < document.wordNum; w++){
				int wordNo = document.wordIdArray[w];//each different word can be denoted in different wordID.
				int wordFre = document.wordFreArray[w];
				n_zv[cluster][wordNo] += wordFre; 
				n_z[cluster] += wordFre; 
			}
		}
	}
	public void gibbsSampling(DocumentSet documentSet)
	{
		for(int i = 0; i < iterNum; i++){
			for(int d = 0; d < D; d++){
				Document document = documentSet.documents.get(d);//get a document from the documentSet
				int cluster = z[d];//
				
				m_z[cluster]--;//the number of the documents in the cluster minus 1
				for(int w = 0; w < document.wordNum; w++){//for each word in the current document 
					int wordNo = document.wordIdArray[w];  //Get the attribute of current document:the number of words 
					int wordFre = document.wordFreArray[w];//Get the attribute of current document:the frequency of each word
					n_zv[cluster][wordNo] -= wordFre;//The attribute of the the cluster (number of the word) minus that of the current document
					n_z[cluster] -= wordFre;//The attribute of the cluster(the frequency of each word) minus that of the current document
				}

				cluster = sampleCluster(d, document);//determine the label of the cluster
				
				z[d] = cluster;
				//After we call the method of sampleCluster,we can restore the attribute of document  and cluster(Fre,word)
				m_z[cluster]++;
				for(int w = 0; w < document.wordNum; w++){
					int wordNo = document.wordIdArray[w];
					int wordFre = document.wordFreArray[w];
					n_zv[cluster][wordNo] += wordFre; 
					n_z[cluster] += wordFre; 
				}
			}
		}
	}

	private int sampleCluster(int d, Document document)//Equation 4
	{ 
		double[] prob = new double[K];//K is the number of cluster
		int[] overflowCount = new int[K];//what is this?

		for(int k = 0; k < K; k++){
			prob[k] = (m_z[k] + alpha) / (D - 1 + alpha0);//The first part of the Equation 4 
			double valueOfRule2 = 1.0;
			int i = 0;
			for(int w=0; w < document.wordNum; w++){
				int wordNo = document.wordIdArray[w];
				int wordFre = document.wordFreArray[w];
				for(int j = 0; j < wordFre; j++){
					if(valueOfRule2 < smallDouble){//smallDouble is the least positive double that can be represented
						overflowCount[k]--;//
						valueOfRule2 *= largeDouble;
					}
					valueOfRule2 *= (n_zv[k][wordNo] + beta + j) 
							 / (n_z[k] + beta0 + i);//The second part of the Equation 4
					i++;
				}
			}
			prob[k] *= valueOfRule2;			
		}
		
		reComputeProbs(prob, overflowCount, K);

		for(int k = 1; k < K; k++){
			prob[k] += prob[k - 1];
		}
		double thred = Math.random() * prob[K - 1];
		int kChoosed;
		for(kChoosed = 0; kChoosed < K; kChoosed++){
			if(thred < prob[kChoosed]){
				break;
			}
		}
		
		return kChoosed;
	}
	
	private void reComputeProbs(double[] prob, int[] overflowCount, int K)
	{
		int max = Integer.MIN_VALUE;
		for(int k = 0; k < K; k++){
			if(overflowCount[k] > max && prob[k] > 0){
				max = overflowCount[k];
			}
		}
		
		for(int k = 0; k < K; k++){			
			if(prob[k] > 0){
				prob[k] = prob[k] * Math.pow(largeDouble, overflowCount[k] - max);
			}
		}		
	}

	public void output(DocumentSet documentSet, String outputPath) throws Exception
	{
		String outputDir = outputPath + dataset + ParametersStr + "/";
		
		File file = new File(outputDir);
		if(!file.exists()){
			if(!file.mkdirs()){
				System.out.println("Failed to create directory:" + outputDir);
			}
		}
		
		outputClusteringResult(outputDir, documentSet);
	}

	public void outputClusteringResult(String outputDir, DocumentSet documentSet) throws Exception
	{
		String outputPath = outputDir + dataset + "ClusteringResult.txt";
		BufferedWriter writer = new BufferedWriter(new OutputStreamWriter
				(new FileOutputStream(outputPath), "UTF-8"));
		for(int d = 0; d < documentSet.D; d++){
			int topic = z[d];
			writer.write(topic + "\n");
		}
		writer.flush();
		writer.close();
	}
}